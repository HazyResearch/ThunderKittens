#include <iostream>
#include <string>
#include <stdlib.h>
#include <float.h>

#define CudaCheckError()    __cudaCheckError( __FILE__, __LINE__ )
inline void __cudaCheckError( const char *file, const int line ) {
    cudaError err = cudaGetLastError();
    if ( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
    // More careful checking. However, this will affect performance.
    // Comment away if needed.
    err = cudaDeviceSynchronize();
    if( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() with sync failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
}

void cpu_gemm(half *a, half *b, half *c, int M, int N, int K) {
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            float s = 0.0;
            for (int k = 0; k < K; k++) {
                s += (float)a[i * K + k] * (float)b[k * N + j];
            }
            c[i * N + j] = (half)s;
        }
    }
}

bool check_value(float abs_tol, float rel_tol, half *h_d_c, half *h_c, int m, int n) {
    for (size_t i = 0; i < m; i++) {
        for (size_t j = 0; j < n; j++) {
            float gpu_value = (float)h_d_c[i * n + j];
            float cpu_value = (float)h_c[i * n + j];
            float diff = abs(gpu_value - cpu_value);
            if (diff > max(abs_tol, cpu_value * rel_tol)) {
                std::cout << "GPU[" << i << ", " << j << "] = " << gpu_value
                << "CPU[" << i << ", " << j << "] = " << cpu_value
                << " Abs Diff: " << diff << std::endl;
                return false;
            }
        }
    }
    return true;
}

int main(int argc, char **argv) {
    constexpr size_t m = 512;
    constexpr size_t n = 512;
    constexpr size_t k = 512;
    constexpr size_t lda = (k + 16 - 1) / 16;
    constexpr size_t ldb = (n + 16 - 1) / 16;
    constexpr size_t ldc = (n + 16 - 1) / 16;
    half alpha = 1.0f;
    half beta = 0.0f;

    size_t size_a = m * k * sizeof(half);
    size_t size_b = k * n * sizeof(half);
    size_t size_c = m * n * sizeof(half);
    
    half *h_a, *h_b, *d_a, *d_b;
    half *h_c, *d_c, *h_d_c;
    
    h_a = (half *)malloc(size_a);
    h_b = (half *)malloc(size_b);
    h_c = (half *)malloc(size_c);
    cudaMalloc(&d_a, size_a);
    cudaMalloc(&d_b, size_b);
    cudaMalloc(&d_c, size_c);
    h_d_c = (half *)malloc(size_c);

    srand(time(0));
    for (size_t i = 0; i < m * k; i++) {
        h_a[i] = (half)(rand() % 10);
    }
    for (size_t i = 0; i < n * k; i++) {
        h_b[i] = (half)(rand() % 10);
    }

    cpu_gemm(h_a, h_b, h_c, m, n, k);

    cudaMemcpy(d_a, h_a, size_a, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size_b, cudaMemcpyHostToDevice);

    cudaStream_t stream;
    cudaStreamCreate(&stream);
    launch_simple_gemm_tt(m, n, k, &alpha, d_a, lda, d_b, ldb, &beta, d_c, ldc, stream);
    CudaCheckError();
    cudaMemcpy(h_d_c, d_c, size_c, cudaMemcpyDeviceToHost);

    constexpr float abs_tol = 5.0e-2f;
    constexpr float rel_tol = 1.0e-2f;

    if (check_value(abs_tol, rel_tol, h_d_c, h_c, m, n)) {
        std::cout << "Test PASSED" << std::endl;
    } else {
        std::cout << "Test FAILED" << std::endl;
    }

    free(h_a);
    free(h_b);
    free(h_c);
    free(h_d_c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
    cudaStreamDestroy(stream);

    return 0;
}
