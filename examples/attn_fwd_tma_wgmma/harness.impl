#include <iostream>
#include <string>
#include <fstream>

#define CudaCheckError()    __cudaCheckError( __FILE__, __LINE__ )
inline void __cudaCheckError( const char *file, const int line ) {
    cudaError err = cudaGetLastError();
    if ( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
    // More careful checking. However, this will affect performance.
    // Comment away if needed.
    err = cudaDeviceSynchronize();
    if( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() with sync failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
}

int main(int argc, char **argv) {
    // TODO: consider doing sequential kernel launches to force batches dimension element to execute sequentially,
    // which may increase the probability of L2 cache hits on KV

    std::cout << "Entered main!" << std::endl;

    // create dummy variables that are the right size
    constexpr int TOTAL_ELEMENTS = ATTN_B*ATTN_H*ATTN_N*ATTN_D;
    constexpr int TOTAL_UNIQUE_ELEMENTS = ATTN_N*ATTN_D;

    float *q = new float[TOTAL_UNIQUE_ELEMENTS];
    float *k = new float[TOTAL_UNIQUE_ELEMENTS];
    float *v = new float[TOTAL_UNIQUE_ELEMENTS];
    float *o_ref = new float[TOTAL_UNIQUE_ELEMENTS];

    bf16 *q_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *k_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *v_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *o_bf = new bf16[TOTAL_ELEMENTS];
    float *o = new float[TOTAL_ELEMENTS];

    std::ifstream infile(argv[1]);

    std::cout << "Starting to enter!" << std::endl;

    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS; i++) infile >> q[i];
    std::cout << "Finished loading Q" << std::endl;
    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS; i++) infile >> k[i];
    std::cout << "Finished loading K" << std::endl;
    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS; i++) infile >> v[i];
    std::cout << "Finished loading V" << std::endl;
    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS; i++) infile >> o_ref[i];
    std::cout << "Finished loading O_REF" << std::endl;

    std::cout << "Finished loading file from " << argv[1] << "!" << std::endl;

    // replicate into heads
    for(int i = 0; i < TOTAL_ELEMENTS; i++) {
        q_bf[i] = __float2bfloat16(q[i % TOTAL_UNIQUE_ELEMENTS]);
        k_bf[i] = __float2bfloat16(k[i % TOTAL_UNIQUE_ELEMENTS]);
        v_bf[i] = __float2bfloat16(v[i % TOTAL_UNIQUE_ELEMENTS]);
    }

    bf16 *d_q, *d_k, *d_v, *d_o;
    cudaMalloc(&d_q, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_k, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_v, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_o, TOTAL_ELEMENTS * sizeof(bf16));

    cudaMemcpy(d_q, q_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_k, k_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_v, v_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);

    CUtensorMap tma_desc_q = {}; 
    CUtensorMap tma_desc_k = {};
    CUtensorMap tma_desc_v = {};
    CUtensorMap tma_desc_o = {};

    tma::create_tensor_map<st_bf<2,4,layout_row>, ATTN_B*ATTN_H*ATTN_N/(2 * 16)>(&tma_desc_q, d_q); 
    tma::create_tensor_map<st_bf<2,4,layout_row>, ATTN_B*ATTN_H*ATTN_N/(2 * 16)>(&tma_desc_k, d_k);
    tma::create_tensor_map<st_bf<2,4,layout_col>, ATTN_B*ATTN_H*ATTN_N/(2 * 16)>(&tma_desc_v, d_v);
    tma::create_tensor_map<st_bf<2,4,layout_row>, ATTN_B*ATTN_H*ATTN_N/(2 * 16)>(&tma_desc_o, d_o);

    CUtensorMap* tma_q_d; 
    CUtensorMap* tma_k_d;
    CUtensorMap* tma_v_d;
    CUtensorMap* tma_o_d;

    cudaMalloc(&tma_q_d, sizeof(CUtensorMap));
    cudaMalloc(&tma_k_d, sizeof(CUtensorMap));
    cudaMalloc(&tma_v_d, sizeof(CUtensorMap));
    cudaMalloc(&tma_o_d, sizeof(CUtensorMap));

    cudaMemcpy(tma_q_d, &tma_desc_q, sizeof(CUtensorMap), cudaMemcpyHostToDevice);
    cudaMemcpy(tma_k_d, &tma_desc_k, sizeof(CUtensorMap), cudaMemcpyHostToDevice);
    cudaMemcpy(tma_v_d, &tma_desc_v, sizeof(CUtensorMap), cudaMemcpyHostToDevice);
    cudaMemcpy(tma_o_d, &tma_desc_o, sizeof(CUtensorMap), cudaMemcpyHostToDevice);

    std::cout << "Allocated and set memory on GPU!" << std::endl;
    
    unsigned long mem_size = kittens::MAX_SHARED_MEMORY;
    
    cudaFuncSetAttribute(
        attend_ker<ATTN_N>,
        cudaFuncAttributeMaxDynamicSharedMemorySize,
        mem_size
    );
    std::cout << "Set max dynamic memory!" << std::endl;

    const int ITER = 100;
    dim3 grid(ATTN_N/(QO_BLOCKS*NUM_WORKERS*kittens::TILE_DIM), ATTN_B*ATTN_H, 1);
    static_assert(ATTN_N % (QO_BLOCKS*NUM_WORKERS*kittens::TILE_DIM) == 0);
    cudaDeviceSynchronize();
    std::cout << "Starting warmup" << std::endl;
    for(int i = 0; i < ITER; i++) {
        attend_ker<ATTN_N><<<grid, BLOCK_SIZE, mem_size>>>(64, d_q, d_k, d_v, d_o, tma_q_d, tma_k_d, tma_v_d, tma_o_d); 
    }
    cudaDeviceSynchronize();
    std::cout << "Starting kernel" << std::endl;
    const auto start = std::chrono::high_resolution_clock::now();
    for(int i = 0; i < ITER; i++) {
        attend_ker<ATTN_N><<<grid, BLOCK_SIZE, mem_size>>>(64, d_q, d_k, d_v, d_o, tma_q_d, tma_k_d, tma_v_d, tma_o_d); 
    }
    cudaDeviceSynchronize();
    const auto finish = std::chrono::high_resolution_clock::now();
    CudaCheckError();
    std::cout << "Finished kernel\n";
    
    // check correctness
    cudaMemcpy(o_bf, d_o, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyDeviceToHost);
    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS; i++) {
        o[i] = __bfloat162float(o_bf[i]);
    }

    bool good = true;
    std::ofstream o_ref_file("printouts/o_ref.txt");
    std::ofstream o_file("printouts/o.txt");
    std::ofstream diff_file("printouts/diff.txt");
    for(int i = 0; i < TOTAL_UNIQUE_ELEMENTS; i++) {
        float diff = o[i] - o_ref[i % TOTAL_UNIQUE_ELEMENTS];
        o_ref_file << o_ref[i % TOTAL_UNIQUE_ELEMENTS] << ' ';
        o_file << o[i] << ' ';
        diff_file << diff << ' ';
        if(abs(diff) > 0.01 || isnan(diff)) {
            good = false;
        }
    }

    std::cout << "Average execution time: " << std::chrono::duration_cast<std::chrono::microseconds>(finish - start).count() / ITER << " us" << std::endl;
    if(good) std::cout << "Correct :)\n";
    else std::cout << "Incorrect :(\n";

    cudaFree(d_q);
    cudaFree(d_k);
    cudaFree(d_v);
    cudaFree(d_o);

    delete[] q, k, v, o, o_ref;
    delete[] q_bf, k_bf, v_bf, o_bf;

    return 0;
}